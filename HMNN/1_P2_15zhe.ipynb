{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7238952b7696fd47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T11:26:10.403404Z",
     "start_time": "2023-11-14T11:26:10.398227Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datasets import get_train_test_data2, MMoE_Dataset,get_train_test_data1\n",
    "from models import MMoE_Model, Transfer_Model, MMoE_Model_Expert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d496c19b2a42fd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T11:26:10.668414Z",
     "start_time": "2023-11-14T11:26:10.662122Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = \"./data/new_data/process_data/mutilsolvent2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f48733c9963a03b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T11:26:10.978957Z",
     "start_time": "2023-11-14T11:26:10.973352Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(file_path).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "957f3fe4a2c9745b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T11:29:20.475583Z",
     "start_time": "2023-11-14T11:29:20.471694Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def get_train_test_data(file_path, test_size,seed,dataset_num):\n",
    "    data = pd.read_csv(file_path).values\n",
    "    x_train_list=[]\n",
    "    y_train_list=[]\n",
    "    x_test_list=[]\n",
    "    y_test_list=[]\n",
    "    for i in range(15):\n",
    "        if i == dataset_num:\n",
    "            cur_data = data[35*i:35*(i+1),:]\n",
    "            transfer_x,transfer_y = cur_data[:, :-4], cur_data[:, -4:]\n",
    "        else:\n",
    "            cur_data = data[35*i:35*(i+1),:]\n",
    "            X, y = cur_data[:, :-4], cur_data[:, -4:]\n",
    "            x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=test_size,random_state=seed)\n",
    "            x_train_list.append(x_train)\n",
    "            y_train_list.append(y_train)\n",
    "            x_test_list.append(x_test)\n",
    "            y_test_list.append(y_test)\n",
    "    x_train, x_test, y_train, y_test = np.concatenate(x_train_list),np.concatenate(x_test_list),np.concatenate(y_train_list),np.concatenate(y_test_list)\n",
    "    print(f\"dataset num {dataset_num}\")\n",
    "    print(f\"the number of train samples is: {len(x_train)}\")\n",
    "    print(f\"the number of test samples is: {len(x_test)}\")\n",
    "    print(f\"the number of transfer samples is: {len(x_test)}\")\n",
    "    return x_train, x_test, y_train, y_test,transfer_x,transfer_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46db1b0481f6abea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T11:29:52.646864Z",
     "start_time": "2023-11-14T11:29:52.535459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset num 0\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n",
      "dataset num 1\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n",
      "dataset num 2\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n",
      "dataset num 3\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n",
      "dataset num 4\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n",
      "dataset num 5\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n",
      "dataset num 6\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n",
      "dataset num 7\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n",
      "dataset num 8\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n",
      "dataset num 9\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n",
      "dataset num 10\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n",
      "dataset num 11\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n",
      "dataset num 12\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n",
      "dataset num 13\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n",
      "dataset num 14\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    x_train, x_test, y_train, y_test,transfer_X,transfer_y = get_train_test_data(file_path,0.2,42,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82dc5a71",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-14T12:00:25.894013Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(file_path='data/new_data/process_data/mutilsolvent2.csv', model_save_dir='./p2results_1', res_dir='./p2results_1', water_model_save_path='water2_model_result/waterdi6zhe6.ckpt', air_model_save_path='air2_model_result/air2di9zhe6.ckpt', water_select_expert_config='water2_res_result/waterdi6zhe6_top2.csv', air_select_expert_config='air2_res_result/air2di9zhe6_top2.csv', input_dim=19, represent_dim=100, pair_embedding_dim=5, expert_num=6, gate_output_dim=10, epochs=1, early_stop_num=200, lr=0.0005, verbose=False, writer_flag=False, batch_size=16, test_size=0.2, seed=42, eps='', frozen=False)\n",
      "\n",
      "\n",
      "\n",
      "====start to train mutilsolvent2.csv====\n",
      "data/new_data/process_data/mutilsolvent2.csv\n",
      "dataset num 0\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train all epochs.\n",
      "\n",
      " Best Model loss_total: 78672.362187, loss1: 0.002382,loss2: 0.015060,loss3: 79.565662,loss4: 11.709820\n",
      "\n",
      "theta1:Parameter containing:\n",
      "tensor([0.9875], requires_grad=True),theta2:Parameter containing:\n",
      "tensor([0.9874], requires_grad=True),theta3:Parameter containing:\n",
      "tensor([1.0122], requires_grad=True),theta4:Parameter containing:\n",
      "tensor([1.0121], requires_grad=True)\n",
      "file:mutilsolvent2.csv, rmse:[0.032675475659511906, 0.03224662495839255, 8.803027967216824, 3.236600248583136], r2:[-0.4467993640440011, -0.7624374781210019, -6015.956659746197, -45227.03873677503],mae:[0.026087597, 0.024604715, 8.802313, 3.236545],mape:[0.37797344, 0.24620257, 0.8499896, 0.78632796]\n",
      "file:mutilsolvent2.csv, rmse:[0.04116331768411843, 0.11112086344138658, 8.98072233833458, 3.2829881696438514], r2:[-0.09485570826817491, -30.031481250211844, -3222.5439760498048, -17120.551020020186],mae:[0.034213364, 0.08817467, 8.976997, 3.2817318],mape:[0.50587004, 0.9569606, 0.86683434, 0.79485035]\n",
      "dataset num 1\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train all epochs.\n",
      "\n",
      " Best Model loss_total: 87239.155313, loss1: 0.086448,loss2: 0.021367,loss3: 88.256545,loss4: 11.128357\n",
      "\n",
      "theta1:Parameter containing:\n",
      "tensor([0.9871], requires_grad=True),theta2:Parameter containing:\n",
      "tensor([0.9874], requires_grad=True),theta3:Parameter containing:\n",
      "tensor([1.0124], requires_grad=True),theta4:Parameter containing:\n",
      "tensor([1.0117], requires_grad=True)\n",
      "file:mutilsolvent2.csv, rmse:[0.053080932224733514, 0.0470809707802269, 9.36216895380185, 3.153534580392523], r2:[-2.804416149935956, -2.770424151594652, -6830.5059635093685, -43027.11805722565],mae:[0.04177314, 0.036250602, 9.361482, 3.1534922],mape:[0.65212274, 0.29335532, 0.9040263, 0.76618165]\n",
      "file:mutilsolvent2.csv, rmse:[0.05294244610703828, 0.03249892284884742, 9.373438590676507, 3.1654415939840552], r2:[-0.82229190238688, -1.4948933155528001, -3531.9942895862596, -15849.857969112636],mae:[0.043123692, 0.026140125, 9.372158, 3.16531],mape:[0.70356596, 0.23447448, 0.9041359, 0.76674396]\n",
      "dataset num 2\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train all epochs.\n",
      "\n",
      " Best Model loss_total: 94428.963125, loss1: 0.062635,loss2: 0.011757,loss3: 95.534061,loss4: 7.618773\n",
      "\n",
      "theta1:Parameter containing:\n",
      "tensor([0.9873], requires_grad=True),theta2:Parameter containing:\n",
      "tensor([0.9874], requires_grad=True),theta3:Parameter containing:\n",
      "tensor([1.0124], requires_grad=True),theta4:Parameter containing:\n",
      "tensor([1.0119], requires_grad=True)\n",
      "file:mutilsolvent2.csv, rmse:[0.08899768219096901, 0.030724431895703178, 9.738016834181021, 2.6049406096850984], r2:[-9.62381561633971, -0.5945250604834493, -7240.934541118346, -29908.20796088654],mae:[0.08055069, 0.027246008, 9.737347, 2.6048923],mape:[1.1350882, 0.2525583, 0.9401028, 0.6328357]\n",
      "file:mutilsolvent2.csv, rmse:[0.08126823032789178, 0.037442587324924954, 9.713572604187215, 2.6180415795377887], r2:[-3.3530338495448593, -1.8549827743144993, -3884.7368693334843, -10759.928633822756],mae:[0.06661598, 0.03153875, 9.712307, 2.6179066],mape:[1.336495, 0.34288502, 0.940066, 0.6342311]\n",
      "dataset num 3\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train all epochs.\n",
      "\n",
      " Best Model loss_total: 96359.245313, loss1: 0.035366,loss2: 0.005151,loss3: 97.437988,loss4: 11.253306\n",
      "\n",
      "theta1:Parameter containing:\n",
      "tensor([0.9873], requires_grad=True),theta2:Parameter containing:\n",
      "tensor([0.9875], requires_grad=True),theta3:Parameter containing:\n",
      "tensor([1.0121], requires_grad=True),theta4:Parameter containing:\n",
      "tensor([1.0113], requires_grad=True)\n",
      "file:mutilsolvent2.csv, rmse:[0.047376117245067746, 0.028341128451964397, 9.644559332558346, 2.8533216093244365], r2:[-2.005647056463147, -0.3560076152016527, -7077.902699493026, -35883.725326373664],mae:[0.038670056, 0.022733686, 9.643902, 2.8531904],mape:[0.4338828, 0.23092405, 0.93102044, 0.6931548]\n",
      "file:mutilsolvent2.csv, rmse:[0.06367241282908763, 0.036189627441566175, 9.612450679657485, 2.8733713263753153], r2:[-1.6830944592987747, -1.5396578944996606, -3855.5711280740493, -12937.552893062602],mae:[0.053004876, 0.029966753, 9.611197, 2.8732984],mape:[0.74257255, 0.31014362, 0.93111694, 0.69617426]\n",
      "dataset num 4\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train all epochs.\n",
      "\n",
      " Best Model loss_total: 82625.542500, loss1: 0.005368,loss2: 0.006256,loss3: 83.589935,loss4: 10.768918\n",
      "\n",
      "theta1:Parameter containing:\n",
      "tensor([0.9875], requires_grad=True),theta2:Parameter containing:\n",
      "tensor([0.9874], requires_grad=True),theta3:Parameter containing:\n",
      "tensor([1.0124], requires_grad=True),theta4:Parameter containing:\n",
      "tensor([1.0120], requires_grad=True)\n",
      "file:mutilsolvent2.csv, rmse:[0.029581661674715074, 0.02422354270058626, 9.106245023350347, 3.098646508350996], r2:[-0.17131031711890943, 0.009064466573539876, -6300.841521686622, -42367.860975085125],mae:[0.02550326, 0.018572727, 9.105547, 3.0986083],mape:[0.31788078, 0.16200799, 0.8790108, 0.752776]\n",
      "file:mutilsolvent2.csv, rmse:[0.035942149703735576, 0.020331718764665885, 9.06695026440357, 3.109759896384153], r2:[0.1440106970395706, 0.21519972217135586, -3455.5930726739734, -15153.444260773445],mae:[0.02991316, 0.017393023, 9.065628, 3.109655],mape:[0.789334, 0.14666581, 0.8786587, 0.7534564]\n",
      "dataset num 5\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train all epochs.\n",
      "\n",
      " Best Model loss_total: 82320.724687, loss1: 0.022155,loss2: 0.029991,loss3: 83.259465,loss4: 11.154702\n",
      "\n",
      "theta1:Parameter containing:\n",
      "tensor([0.9874], requires_grad=True),theta2:Parameter containing:\n",
      "tensor([0.9873], requires_grad=True),theta3:Parameter containing:\n",
      "tensor([1.0123], requires_grad=True),theta4:Parameter containing:\n",
      "tensor([1.0116], requires_grad=True)\n",
      "file:mutilsolvent2.csv, rmse:[0.04066356635959065, 0.027674615685020724, 8.997884289759151, 3.0514223253095367], r2:[-1.2117932641739215, -0.2943104722719607, -6144.736708398388, -41057.81088726958],mae:[0.03517126, 0.022198774, 8.997171, 3.051303],mape:[0.3683634, 0.2059225, 0.86851656, 0.7412804]\n",
      "file:mutilsolvent2.csv, rmse:[0.055942647643160405, 0.019976308293686976, 8.953697199619857, 3.057549972063423], r2:[-1.076130980285547, 0.25695535983531137, -3395.8447183138837, -14646.51980869829],mae:[0.04805264, 0.017068295, 8.952322, 3.0572808],mape:[0.51077074, 0.16036187, 0.8680814, 0.7407811]\n",
      "dataset num 6\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train all epochs.\n",
      "\n",
      " Best Model loss_total: 94980.148438, loss1: 0.006658,loss2: 0.007538,loss3: 96.073806,loss4: 12.086076\n",
      "\n",
      "theta1:Parameter containing:\n",
      "tensor([0.9875], requires_grad=True),theta2:Parameter containing:\n",
      "tensor([0.9874], requires_grad=True),theta3:Parameter containing:\n",
      "tensor([1.0123], requires_grad=True),theta4:Parameter containing:\n",
      "tensor([1.0115], requires_grad=True)\n",
      "file:mutilsolvent2.csv, rmse:[0.02562881695890694, 0.027356662000690507, 9.713708091039678, 3.090327209382101], r2:[0.12177120906187033, -0.26710044896879737, -7152.1319381113335, -42128.32299886418],mae:[0.020084219, 0.022938509, 9.712902, 3.0902843],mape:[0.2734392, 0.20678169, 0.9375542, 0.7507472]\n",
      "file:mutilsolvent2.csv, rmse:[0.035978930371588495, 0.021301836536370255, 9.652628296595005, 3.0989134884108633], r2:[0.140305027554547, 0.1782794425697829, -3999.891007476271, -14993.04727046934],mae:[0.031034261, 0.017949354, 9.651508, 3.0987937],mape:[0.6187066, 0.17136857, 0.93664527, 0.75090104]\n",
      "dataset num 7\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train all epochs.\n",
      "\n",
      " Best Model loss_total: 96653.746875, loss1: 0.006621,loss2: 0.029898,loss3: 97.744717,loss4: 11.673859\n",
      "\n",
      "theta1:Parameter containing:\n",
      "tensor([0.9875], requires_grad=True),theta2:Parameter containing:\n",
      "tensor([0.9874], requires_grad=True),theta3:Parameter containing:\n",
      "tensor([1.0122], requires_grad=True),theta4:Parameter containing:\n",
      "tensor([1.0117], requires_grad=True)\n",
      "file:mutilsolvent2.csv, rmse:[0.029244532119221147, 0.0579852415093078, 9.660124658763548, 3.1719518191802165], r2:[-0.14343292813511388, -4.6967009351816955, -7071.7042702079625, -44397.11915082134],mae:[0.024864793, 0.05300393, 9.659459, 3.1719055],mape:[0.31045973, 0.5269918, 0.93238705, 0.77057517]\n",
      "file:mutilsolvent2.csv, rmse:[0.03586862776369127, 0.05119016044000237, 9.604918698031794, 3.1856127369034493], r2:[0.14535447358773212, -3.709870364617955, -3976.426774539981, -15856.551253770456],mae:[0.030304037, 0.045914147, 9.603728, 3.185489],mape:[0.61523503, 0.4491958, 0.9322184, 0.7719252]\n",
      "dataset num 8\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train all epochs.\n",
      "\n",
      " Best Model loss_total: 92189.907500, loss1: 0.042208,loss2: 0.004541,loss3: 93.271440,loss4: 10.170065\n",
      "\n",
      "theta1:Parameter containing:\n",
      "tensor([0.9873], requires_grad=True),theta2:Parameter containing:\n",
      "tensor([0.9875], requires_grad=True),theta3:Parameter containing:\n",
      "tensor([1.0124], requires_grad=True),theta4:Parameter containing:\n",
      "tensor([1.0119], requires_grad=True)\n",
      "file:mutilsolvent2.csv, rmse:[0.034691211806848664, 0.02353985608925296, 9.64504779778122, 3.009653296036158], r2:[-0.6090323241639102, 0.060591598503851984, -7048.678091223033, -39964.21831480641],mae:[0.026181865, 0.020784227, 9.644373, 3.009609],mape:[0.33163762, 0.18431225, 0.93091714, 0.7311467]\n",
      "file:mutilsolvent2.csv, rmse:[0.04432604160445174, 0.03204802525972481, 9.585980080258935, 3.0218692625636296], r2:[-0.30409112266839045, -0.8354503163324767, -3973.951252447975, -14286.590246851472],mae:[0.03576017, 0.02457057, 9.584787, 3.0217655],mape:[0.50334173, 0.23049736, 0.9305491, 0.7322647]\n",
      "dataset num 9\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train all epochs.\n",
      "\n",
      " Best Model loss_total: 92212.688125, loss1: 0.005041,loss2: 0.002000,loss3: 93.254282,loss4: 11.710276\n",
      "\n",
      "theta1:Parameter containing:\n",
      "tensor([0.9875], requires_grad=True),theta2:Parameter containing:\n",
      "tensor([0.9875], requires_grad=True),theta3:Parameter containing:\n",
      "tensor([1.0122], requires_grad=True),theta4:Parameter containing:\n",
      "tensor([1.0115], requires_grad=True)\n",
      "file:mutilsolvent2.csv, rmse:[0.028155007803267428, 0.02139415002204276, 9.459399954413525, 3.048653577442656], r2:[-0.05986196694727197, 0.22312684248656411, -6778.899671881951, -41038.37767130539],mae:[0.02184445, 0.018178377, 9.458709, 3.0486012],mape:[0.3080463, 0.18218589, 0.9129702, 0.74061716]\n",
      "file:mutilsolvent2.csv, rmse:[0.033817781594342136, 0.017554138460908593, 9.396284432306873, 3.061367370424003], r2:[0.23956029590859562, 0.4547015282929282, -3840.8542038349015, -14648.323432833518],mae:[0.027768169, 0.013860842, 9.395067, 3.0612335],mape:[0.85243416, 0.13372801, 0.91243994, 0.7418442]\n",
      "dataset num 10\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train all epochs.\n",
      "\n",
      " Best Model loss_total: 92091.621563, loss1: 0.005031,loss2: 0.031812,loss3: 93.159991,loss4: 6.623179\n",
      "\n",
      "theta1:Parameter containing:\n",
      "tensor([0.9875], requires_grad=True),theta2:Parameter containing:\n",
      "tensor([0.9873], requires_grad=True),theta3:Parameter containing:\n",
      "tensor([1.0123], requires_grad=True),theta4:Parameter containing:\n",
      "tensor([1.0117], requires_grad=True)\n",
      "file:mutilsolvent2.csv, rmse:[0.039332126860919595, 0.054649448354750566, 9.571992438651709, 2.4140009702476695], r2:[-1.0685143303645455, -4.072171568732738, -6941.191294742556, -25699.450450922788],mae:[0.029660115, 0.04707389, 9.571313, 2.4139442],mape:[0.35117686, 0.38284326, 0.92382956, 0.58643216]\n",
      "file:mutilsolvent2.csv, rmse:[0.04396076725363624, 0.05772552568885847, 9.508529046797358, 2.424329338538644], r2:[-0.2841757268248808, -4.869624860092151, -3945.5029488478135, -9172.199212595046],mae:[0.0373039, 0.053068735, 9.507298, 2.4241838],mape:[0.5771224, 0.43297964, 0.9234919, 0.5874686]\n",
      "dataset num 11\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train all epochs.\n",
      "\n",
      " Best Model loss_total: 83126.320000, loss1: 0.008564,loss2: 0.001933,loss3: 84.094118,loss4: 12.648524\n",
      "\n",
      "theta1:Parameter containing:\n",
      "tensor([0.9874], requires_grad=True),theta2:Parameter containing:\n",
      "tensor([0.9875], requires_grad=True),theta3:Parameter containing:\n",
      "tensor([1.0124], requires_grad=True),theta4:Parameter containing:\n",
      "tensor([1.0114], requires_grad=True)\n",
      "file:mutilsolvent2.csv, rmse:[0.02935515606942721, 0.025754780483942974, 9.154916711800277, 3.207655368529611], r2:[-0.15238764482656775, -0.1278420133856173, -6349.707774363533, -45404.11900193218],mae:[0.023697529, 0.020468863, 9.154202, 3.2076163],mape:[0.32126737, 0.17672247, 0.8835439, 0.7792501]\n",
      "file:mutilsolvent2.csv, rmse:[0.030040590558356724, 0.026914710030496634, 9.087765746710785, 3.219532251207455], r2:[0.4003276478940605, -0.26582357313346794, -3624.7509076352885, -16202.588204220028],mae:[0.025549214, 0.022953432, 9.086527, 3.219466],mape:[0.71680623, 0.18967812, 0.88288546, 0.7802372]\n",
      "dataset num 12\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train all epochs.\n",
      "\n",
      " Best Model loss_total: 95844.790313, loss1: 0.040850,loss2: 0.003580,loss3: 96.910707,loss4: 11.645018\n",
      "\n",
      "theta1:Parameter containing:\n",
      "tensor([0.9873], requires_grad=True),theta2:Parameter containing:\n",
      "tensor([0.9875], requires_grad=True),theta3:Parameter containing:\n",
      "tensor([1.0121], requires_grad=True),theta4:Parameter containing:\n",
      "tensor([1.0124], requires_grad=True)\n",
      "file:mutilsolvent2.csv, rmse:[0.029424128728699043, 0.029197839398162204, 9.488711426281759, 3.329351494679117], r2:[-0.1580283105889626, -0.45135829419056206, -6822.788741242035, -48942.568080143894],mae:[0.024564266, 0.024221132, 9.488008, 3.3293152],mape:[0.28905, 0.20523466, 0.9157442, 0.808812]\n",
      "file:mutilsolvent2.csv, rmse:[0.04312110436464696, 0.03175464538380813, 9.417335238958508, 3.3402870285600463], r2:[-0.23575796196658616, -0.7485246343267131, -3913.8481710271735, -17454.298710493018],mae:[0.035913777, 0.030283496, 9.416121, 3.3401957],mape:[1.1772085, 0.26071674, 0.9151982, 0.80950904]\n",
      "dataset num 13\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train all epochs.\n",
      "\n",
      " Best Model loss_total: 96452.605625, loss1: 0.041073,loss2: 0.008629,loss3: 97.522417,loss4: 13.060181\n",
      "\n",
      "theta1:Parameter containing:\n",
      "tensor([0.9873], requires_grad=True),theta2:Parameter containing:\n",
      "tensor([0.9874], requires_grad=True),theta3:Parameter containing:\n",
      "tensor([1.0121], requires_grad=True),theta4:Parameter containing:\n",
      "tensor([1.0113], requires_grad=True)\n",
      "file:mutilsolvent2.csv, rmse:[0.05390343416848391, 0.027974002950213475, 9.571655677427316, 3.269095151340889], r2:[-3.0688158415394104, -0.33461742950130224, -7034.183687476849, -47054.15869585312],mae:[0.04259162, 0.023337135, 9.570965, 3.26905],mape:[0.44236326, 0.19277537, 0.9234833, 0.79419386]\n",
      "file:mutilsolvent2.csv, rmse:[0.0661358834120913, 0.03764653589316874, 9.472009481786158, 3.2804392948449888], r2:[-1.9387220764487525, -1.3581044242691944, -4042.7608332042764, -16867.043580809775],mae:[0.058337573, 0.030306492, 9.470953, 3.2803252],mape:[0.82544374, 0.23926811, 0.92235345, 0.7951011]\n",
      "dataset num 14\n",
      "the number of train samples is: 392\n",
      "the number of test samples is: 98\n",
      "the number of transfer samples is: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train all epochs.\n",
      "\n",
      " Best Model loss_total: 87351.810938, loss1: 0.102920,loss2: 0.010716,loss3: 88.366333,loss4: 12.039598\n",
      "\n",
      "theta1:Parameter containing:\n",
      "tensor([0.9872], requires_grad=True),theta2:Parameter containing:\n",
      "tensor([0.9874], requires_grad=True),theta3:Parameter containing:\n",
      "tensor([1.0124], requires_grad=True),theta4:Parameter containing:\n",
      "tensor([1.0116], requires_grad=True)\n",
      "file:mutilsolvent2.csv, rmse:[0.05701325807195492, 0.048326957796150025, 9.363433620214128, 3.235749767978686], r2:[-3.565678051265947, -3.002500655234128, -7077.98899128886, -46100.313130218725],mae:[0.04855852, 0.04047212, 9.362778, 3.2357113],mape:[0.6653318, 0.41960484, 0.9031799, 0.7860896]\n",
      "file:mutilsolvent2.csv, rmse:[0.061812582319564505, 0.040475661576340485, 9.244515107365691, 3.244781265527864], r2:[-1.5634924423350838, -1.6801095882155361, -3828.7584651376474, -16473.611137366523],mae:[0.05151345, 0.03221558, 9.243343, 3.2446785],mape:[6.539258, 0.30005205, 0.9021518, 0.7865416]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def create_dir(file_path):\n",
    "    if not os.path.exists(os.path.dirname(file_path)):\n",
    "        os.makedirs(os.path.dirname(file_path))\n",
    "\n",
    "\n",
    "def trainer(water_model,water_select_expert,air_model,air_select_expert,train_loader, model, model_save_path, device ,lr, epochs, early_stop_num, verbose=True, writer_flag=False):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss(reduction='mean')\n",
    "    params = model.parameters()\n",
    "    theta1 = model.theta1\n",
    "    theta2 = model.theta2\n",
    "    theta3 = model.theta3\n",
    "    theta4 = model.theta4\n",
    "\n",
    "    water_model=water_model.to(device)\n",
    "    air_model=air_model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(params, lr=lr)\n",
    "\n",
    "    create_dir(model_save_path)\n",
    "\n",
    "    n_epochs, best_loss, step, early_stop_count = epochs, math.inf, 0, 0\n",
    "\n",
    "\n",
    "    best_loss1 = best_loss2 = best_loss3 = best_loss4 = math.inf\n",
    "    writer = None\n",
    "    if writer_flag:\n",
    "        writer = SummaryWriter()\n",
    "    ran = range(n_epochs)\n",
    "    if not verbose:\n",
    "        ran = tqdm(range(n_epochs), position=0, leave=True)\n",
    "    for epoch in ran:\n",
    "        model.train()\n",
    "        loss_total_record = []\n",
    "        loss1_record = []\n",
    "        loss2_record = []\n",
    "        loss3_record = []\n",
    "        loss4_record = []\n",
    "\n",
    "        for x, y1, y2, y3, y4 in train_loader:\n",
    "\n",
    "            x, y1, y2, y3, y4 = x.to(device), y1.to(device), y2.to(device), y3.to(device), y4.to(device),\n",
    "\n",
    "\n",
    "            water_expert_represents = water_model(x)[:, water_select_expert, :]\n",
    "            air_expert_represents = air_model(x)[:, air_select_expert, :]\n",
    "            \n",
    "            \n",
    "            pred1, pred2, pred3, pred4 = model(x,water_expert_represents,air_expert_represents)\n",
    "\n",
    "            loss1 = criterion(pred1, y1)\n",
    "            loss2 = criterion(pred2, y2)\n",
    "            loss3 = criterion(pred3, y3)\n",
    "            loss4 = criterion(pred4, y4)\n",
    "\n",
    "\n",
    "            loss_total = loss1 / (theta1 ** 2) +  loss2 / (theta2 ** 2) + loss3 / (theta3 ** 2)*1000 + loss4 / (theta4 ** 2) + 2 * (torch.log(theta1) +torch.log(theta2) + torch.log(theta3) + torch.log(theta4))\n",
    "            optimizer.zero_grad()\n",
    "            loss_total.backward()\n",
    "            optimizer.step()\n",
    "            step += 1\n",
    "\n",
    "            loss_total_record.append(loss_total.detach().item())\n",
    "            loss1_record.append(loss1.detach().item())\n",
    "            loss2_record.append(loss2.detach().item())\n",
    "            loss3_record.append(loss3.detach().item())\n",
    "            loss4_record.append(loss4.detach().item())\n",
    "\n",
    "        mean_train_loss_total = sum(loss_total_record) / len(loss_total_record)\n",
    "        mean_train_loss1 = sum(loss1_record) / len(loss1_record)\n",
    "        mean_train_loss2 = sum(loss2_record) / len(loss2_record)\n",
    "        mean_train_loss3 = sum(loss3_record) / len(loss3_record)\n",
    "        mean_train_loss4 = sum(loss4_record) / len(loss4_record)\n",
    "        if writer_flag:\n",
    "            writer.add_scalar('Loss_total/train', mean_train_loss_total, step)\n",
    "            writer.add_scalar('Loss1/train', mean_train_loss1, step)\n",
    "            writer.add_scalar('Loss2/train', mean_train_loss2, step)\n",
    "            writer.add_scalar('Loss3/train', mean_train_loss3, step)\n",
    "            writer.add_scalar('Loss4/train', mean_train_loss4, step)\n",
    "\n",
    "        if verbose and epoch % 100 == 99:\n",
    "            print(\n",
    "                f'Epoch [{epoch + 1}/{n_epochs}]: Train loss_total: {mean_train_loss_total:.6f}, loss1: {mean_train_loss1:.6f},loss2: {mean_train_loss2:.6f},loss3: {mean_train_loss3:.6f},loss4: {mean_train_loss4:.6f}')\n",
    "\n",
    "        if mean_train_loss_total < best_loss:\n",
    "            best_loss = mean_train_loss_total\n",
    "            best_loss1 = mean_train_loss1\n",
    "            best_loss2 = mean_train_loss2\n",
    "            best_loss3 = mean_train_loss3\n",
    "            best_loss4 = mean_train_loss4\n",
    "\n",
    "            torch.save(model.state_dict(), model_save_path)  # Save your best model\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"\\nSave with loss_total: {mean_train_loss_total:.6f}, loss1: {mean_train_loss1:.6f},loss2: {mean_train_loss2:.6f},loss3: {mean_train_loss3:.6f},loss4: {mean_train_loss4:.6f}\")\n",
    "            early_stop_count = 0\n",
    "        else:\n",
    "            early_stop_count += 1\n",
    "\n",
    "        if early_stop_count >= early_stop_num:\n",
    "            print(f'\\nModel is not improving, so we halt the training session at epoch: {epoch + 1}.')\n",
    "            print(\n",
    "                f\"\\n Best Model loss_total: {best_loss:.6f}, loss1: {best_loss1:.6f},loss2: {best_loss2:.6f},loss3: {best_loss3:.6f},loss4: {best_loss4:.6f}\")\n",
    "            print(f\"\\ntheta1:{theta1},theta2:{theta2},theta3:{theta3},theta4:{theta4}\")\n",
    "            return\n",
    "\n",
    "    print(f'\\nTrain all epochs.')\n",
    "    print(\n",
    "        f\"\\n Best Model loss_total: {best_loss:.6f}, loss1: {best_loss1:.6f},loss2: {best_loss2:.6f},loss3: {best_loss3:.6f},loss4: {best_loss4:.6f}\")\n",
    "    print(f\"\\ntheta1:{theta1},theta2:{theta2},theta3:{theta3},theta4:{theta4}\")\n",
    "\n",
    "\n",
    "\n",
    "def predict(model,device,data,y,water_expert_represents_test,air_expert_represents_test):\n",
    "    data = torch.Tensor(data).to(device)\n",
    "    y1 = torch.Tensor(y[:,0]).to(device)\n",
    "    y2 = torch.Tensor(y[:,1]).to(device)\n",
    "    y3 = torch.Tensor(y[:,2]).to(device)\n",
    "    y4 = torch.Tensor(y[:,3]).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss(reduction=\"mean\")\n",
    "    model.eval()\n",
    "    pred1,pred2,pred3,pred4= model(data,water_expert_represents_test,air_expert_represents_test)\n",
    "\n",
    "    pred_list = [pred1,pred2,pred3,pred4]\n",
    "    rmse1  = criterion(pred1,y1).item()**0.5\n",
    "    rmse2  = criterion(pred2,y2).item() ** 0.5\n",
    "    rmse3  = criterion(pred3,y3).item()** 0.5\n",
    "    rmse4  = criterion(pred4,y4).item()** 0.5\n",
    "    rmse_list = [rmse1,rmse2,rmse3,rmse4]\n",
    "\n",
    "    r1 = r2_score(y1.cpu().detach().numpy(),pred1.cpu().detach().numpy())\n",
    "    r2 = r2_score(y2.cpu().detach().numpy(),pred2.cpu().detach().numpy())\n",
    "    r3 = r2_score(y3.cpu().detach().numpy(),pred3.cpu().detach().numpy())\n",
    "    r4 = r2_score(y4.cpu().detach().numpy(),pred4.cpu().detach().numpy())\n",
    "\n",
    "    m1 = mean_absolute_error(y1.cpu().detach().numpy(),pred1.cpu().detach().numpy())\n",
    "    m2 = mean_absolute_error(y2.cpu().detach().numpy(),pred2.cpu().detach().numpy())\n",
    "    m3 = mean_absolute_error(y3.cpu().detach().numpy(),pred3.cpu().detach().numpy())\n",
    "    m4 = mean_absolute_error(y4.cpu().detach().numpy(),pred4.cpu().detach().numpy())\n",
    "\n",
    "    mape1 = mean_absolute_percentage_error(y1.cpu().detach().numpy(),pred1.cpu().detach().numpy())\n",
    "    mape2 = mean_absolute_percentage_error(y2.cpu().detach().numpy(),pred2.cpu().detach().numpy())\n",
    "    mape3 = mean_absolute_percentage_error(y3.cpu().detach().numpy(),pred3.cpu().detach().numpy())\n",
    "    mape4 = mean_absolute_percentage_error(y4.cpu().detach().numpy(),pred4.cpu().detach().numpy())\n",
    "\n",
    "    r_list = [r1,r2,r3,r4]\n",
    "    m_list = [m1,m2,m3,m4]\n",
    "    mape_list = [mape1,mape2,mape3,mape4]\n",
    "    return rmse_list,r_list,m_list,pred_list,mape_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##%% md\n",
    "import numpy as np\n",
    "##%%\n",
    "FILE_DIR = \"../data/process_data\"\n",
    "MODEL_DIR = \"./models\"\n",
    "RESULT_DIR=\"./results\"\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Train')\n",
    "    parser.add_argument('--file_path', type=str, default='data/new_data/process_data/mutilsolvent2.csv',help='')\n",
    "    parser.add_argument('--model_save_dir', type=str,default=\"./p2results_1\", help='')\n",
    "    parser.add_argument('--res_dir', type=str,default=\"./p2results_1\", help='')\n",
    "\n",
    "    parser.add_argument('--water_model_save_path', type=str,default=\"water2_model_result/waterdi6zhe6.ckpt\", help='')\n",
    "    parser.add_argument('--air_model_save_path', default=\"air2_model_result/air2di9zhe6.ckpt\",type=str, help='')\n",
    "    parser.add_argument('--water_select_expert_config', default=\"water2_res_result/waterdi6zhe6_top2.csv\",type=str, help='')\n",
    "    parser.add_argument('--air_select_expert_config', type=str, default=\"air2_res_result/air2di9zhe6_top2.csv\",help='')\n",
    "\n",
    "    parser.add_argument('--input_dim', type=int,default=19, help='')\n",
    "    parser.add_argument('--represent_dim', type=int, default=100, help='')\n",
    "    parser.add_argument('--pair_embedding_dim', type=int, default=5, help='')\n",
    "    parser.add_argument('--expert_num', type=int, default=6, help='')\n",
    "    parser.add_argument('--gate_output_dim', type=int, default=10, help='')\n",
    "    parser.add_argument('--epochs',  type=int, default=1, help='')\n",
    "    parser.add_argument('--early_stop_num',  type=int, default=200, help='')\n",
    "\n",
    "    parser.add_argument('--lr', type=float, default=0.0005, help='')\n",
    "    parser.add_argument(\"--verbose\", action=\"store_true\", help=\"\")\n",
    "    parser.add_argument(\"--writer_flag\", action=\"store_true\", help=\"\")\n",
    "    parser.add_argument('--batch_size',  type=int, default=16, help='')\n",
    "    parser.add_argument('--test_size', type=float, default=0.2, help='')\n",
    "    parser.add_argument('--seed',  type=int, default=42, help='')\n",
    "    parser.add_argument('--eps', type=str, default=\"\", help='')\n",
    "    parser.add_argument(\"--frozen\", action=\"store_true\", help=\"\")\n",
    "\n",
    "    # device = \"cuda:5\" if torch.cuda.is_available() else \"cpu\"\n",
    "    device = \"cpu\"\n",
    "    karg = parser.parse_args(args=[])\n",
    "    print(karg)\n",
    "    file_name = os.path.basename(karg.file_path)\n",
    "    print(f\"\\n\\n\\n====start to train {file_name}====\")\n",
    "    model_save_path =  os.path.join(karg.model_save_dir,file_name.split(\".\")[0]+\".ckpt\")\n",
    "    print(karg.file_path)\n",
    "    create_dir(model_save_path)\n",
    "\n",
    "    for k in range(0,15):\n",
    "        x_train, x_test, y_train, y_test,transfer_X,transfer_y = get_train_test_data(file_path,karg.test_size,karg.seed,k)\n",
    "\n",
    "        water_model_save_path = karg.water_model_save_path\n",
    "        air_model_save_path = karg.air_model_save_path\n",
    "        model_water = MMoE_Model_Expert()\n",
    "        model_water.load_state_dict(torch.load(water_model_save_path,map_location=torch.device(device)))\n",
    "        model_air = MMoE_Model_Expert()\n",
    "        model_air.load_state_dict(torch.load(air_model_save_path,map_location=torch.device(device)))\n",
    "\n",
    "        if karg.frozen:\n",
    "            model_water.pair_embedding_layer_list.requires_grad_(False)\n",
    "            model_water.expert_list.requires_grad_(False)\n",
    "            model_water.beta_layer.requires_grad_(False)\n",
    "            model_air.pair_embedding_layer_list.requires_grad_(False)\n",
    "            model_air.expert_list.requires_grad_(False)\n",
    "            model_air.beta_layer.requires_grad_(False)\n",
    "\n",
    "\n",
    "\n",
    "        water_top2_index_df  = pd.read_csv(karg.water_select_expert_config)\n",
    "        air_top2_index_df = pd.read_csv(karg.air_select_expert_config)\n",
    "\n",
    "        water_select_expert = torch.Tensor(water_top2_index_df.values).long()\n",
    "        air_select_expert = torch.Tensor(air_top2_index_df.values).long()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        train_dataset = MMoE_Dataset(x_train, y_train[:, 0], y_train[:, 1], y_train[:, 2], y_train[:, 3])\n",
    "        train_dataloader = DataLoader(train_dataset, karg.batch_size, shuffle=True, pin_memory=True)\n",
    "        model = Transfer_Model(input_dim=karg.input_dim, represent_dim=karg.represent_dim, pair_embedding_dim=karg.pair_embedding_dim,\n",
    "                           expert_num=karg.expert_num,gate_output_dim=karg.gate_output_dim).to(device)\n",
    "\n",
    "        trainer(model_water,water_select_expert,model_air,air_select_expert,train_dataloader, model, model_save_path, device, karg.lr, karg.epochs, karg.early_stop_num, karg.verbose, karg.writer_flag)\n",
    "        water_expert_represents_test = model_water(torch.Tensor(x_test).to(device))[:, water_select_expert, :]\n",
    "        air_expert_represents_test = model_air(torch.Tensor(x_test).to(device))[:, air_select_expert, :]\n",
    "        rmse, r2, m, _, mape = predict(model, device, x_test, y_test,water_expert_represents_test,air_expert_represents_test)\n",
    "        print(f\"file:{file_name}, rmse:{rmse}, r2:{r2},mae:{m},mape:{mape}\")\n",
    "        result = pd.DataFrame([rmse + r2 + m + mape],\n",
    "                              columns=[\"eads_rmse\", \"delta_e_rmse\", \"eb_rmse\", \"db_rmse\", \"eads_r2\", \"delta_e_r2\", \"eb_r2\",\n",
    "                                       \"db_r2\", \"eads_mae\",\n",
    "                                       \"delta_e_mae\", \"eb_mae\", \"db_mae\", \"eads_mape\", \"delta_e_mape\", \"eb_mape\",\n",
    "                                       \"db_mape\"])\n",
    "        result_path = os.path.join(karg.res_dir, file_name.split(\".\")[0]+str(k)+\"_test.csv\")\n",
    "        create_dir(result_path)\n",
    "        result.to_csv(result_path, index_label='num')\n",
    "        \n",
    "        water_expert_represents_test = model_water(torch.Tensor(transfer_X).to(device))[:, water_select_expert, :]\n",
    "        air_expert_represents_test = model_air(torch.Tensor(transfer_X).to(device))[:, air_select_expert, :]\n",
    "        rmse, r2, m, _, mape = predict(model, device, transfer_X, transfer_y,water_expert_represents_test,air_expert_represents_test)\n",
    "        print(f\"file:{file_name}, rmse:{rmse}, r2:{r2},mae:{m},mape:{mape}\")\n",
    "        result = pd.DataFrame([rmse + r2 + m + mape],\n",
    "                              columns=[\"eads_rmse\", \"delta_e_rmse\", \"eb_rmse\", \"db_rmse\", \"eads_r2\", \"delta_e_r2\", \"eb_r2\",\n",
    "                                       \"db_r2\", \"eads_mae\",\n",
    "                                       \"delta_e_mae\", \"eb_mae\", \"db_mae\", \"eads_mape\", \"delta_e_mape\", \"eb_mape\",\n",
    "                                       \"db_mape\"])\n",
    "        result_path = os.path.join(karg.res_dir, file_name.split(\".\")[0]+str(k)+\"_transfer.csv\")\n",
    "        create_dir(result_path)\n",
    "        # \n",
    "        result.to_csv(result_path, index_label='num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda363b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad8e43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e3c9db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbd4bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0a88a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeed0c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a5888e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e93101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14120d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
